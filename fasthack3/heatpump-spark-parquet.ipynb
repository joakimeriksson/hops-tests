{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035e6503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>84</td><td>application_1638826983412_0024</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hops3-master-upgrade.internal.cloudapp.net:8089/proxy/application_1638826983412_0024/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://hops3-worker-1.internal.cloudapp.net:8044/node/containerlogs/container_e10_1638826983412_0024_01_000001/Kringlan__meb10180\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Job for storing the heatpump data to a parquet file on HDFS\n",
    "#\n",
    "# Import Libraries\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, BooleanType\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, TimestampType, LongType\n",
    "from pyspark.sql import functions\n",
    "from hops import kafka\n",
    "from hops import tls\n",
    "from hops import hdfs\n",
    "\n",
    "\n",
    "# Setup the Schema for storing the data\n",
    "schema = StructType([\n",
    "    StructField(\"BrineOutTemp\", IntegerType(), True),\n",
    "    StructField(\"BrineInTemp\", IntegerType(), True),\n",
    "    StructField(\"OutdoorTemp\", IntegerType(), True),\n",
    "    StructField(\"SupplylineTemp\", IntegerType(), True),\n",
    "    StructField(\"ReturnlineTemp\", IntegerType(), True),\n",
    "    StructField(\"BrinepumpSpeed\", IntegerType(), True),\n",
    "    StructField(\"HotwaterTemp\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True)])\n",
    "\n",
    "# Setup Topic namnet\n",
    "TOPIC_NAME = \"heatpump\"\n",
    "config = kafka.get_kafka_default_config()\n",
    "\n",
    "# Setup Spark Kafka stream\n",
    "dfk = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", kafka.get_broker_endpoints()) \\\n",
    "  .option(\"kafka.security.protocol\",kafka.get_security_protocol()) \\\n",
    "  .option(\"kafka.ssl.truststore.location\", tls.get_trust_store()) \\\n",
    "  .option(\"kafka.ssl.truststore.password\", tls.get_key_store_pwd()) \\\n",
    "  .option(\"kafka.ssl.keystore.location\", tls.get_key_store()) \\\n",
    "  .option(\"kafka.ssl.keystore.password\", tls.get_key_store_pwd()) \\\n",
    "  .option(\"kafka.ssl.key.password\", tls.get_trust_store_pwd()) \\\n",
    "  .option(\"kafka.ssl.endpoint.identification.algorithm\", \"\") \\\n",
    "  .option(\"subscribe\", TOPIC_NAME) \\\n",
    "  .load()\n",
    "\n",
    "# If in need of reading from start!\n",
    "#  .option(\"startingOffsets\", \"earliest\") \\\n",
    "\n",
    "# Test Stream to Parquet fil\n",
    "PARQ_PATH  = \"/Projects/\" + hdfs.project_name() + \"/Jupyter/Data/heatpump3.parquet\"\n",
    "CHECK_PATH =  \"/Projects/\" + hdfs.project_name() + \"/Jupyter/Data/heatpump3_checkpoint/\"\n",
    "\n",
    "df_output = dfk \\\n",
    "        .selectExpr(\"CAST(value AS STRING)\") \\\n",
    "        .select(functions.from_json(\"value\", schema=schema).alias(\"data\"))\n",
    "\n",
    "# parquet sink example - will store just once!\n",
    "targetParquetHDFS = df_output \\\n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\")\\\n",
    "    .option(\"path\", PARQ_PATH) \\\n",
    "    .option(\"checkpointLocation\", CHECK_PATH) \\\n",
    "    .trigger(once=True) \\\n",
    "    .start()\n",
    "\n",
    "#    .trigger(processingTime=\"120 seconds\") \\\n",
    "\n",
    "\n",
    "targetParquetHDFS.awaitTermination()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889772c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e778ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}